# 常见的 agent 模式

本文件夹包含了不同常见 agent 模式的示例。

## 确定性流程

一个常见的策略是将任务分解成一系列小步骤。每个步骤可以由一个 agent 执行，一个 agent 的输出会作为下一个 agent 的输入。例如，如果你的任务是生成一个故事，你可以将其分解为以下步骤：

1. 生成大纲
2. 生成故事内容
3. 生成结尾

这些步骤每一个都可以由一个 agent 来执行。一个 agent 的输出会作为下一个 agent 的输入。

查看 [`deterministic.py`](./deterministic.py) 文件获取这种模式的示例。

## 任务交接和路由

在很多情况下，你会有专门处理特定任务的子 agent。你可以使用任务交接来将任务路由到合适的 agent。

例如，你可能有一个前线 agent 接收请求，然后根据请求的语言将任务交给专门的 agent。
查看 [`routing.py`](./routing.py) 文件获取这种模式的示例。

## 将 agent 作为工具

任务交接的思维模型是新 agent "接管"任务。它可以看到之前的对话历史，并从那一刻起掌控对话。但这并不是使用 agent 的唯一方式。你也可以将 agent 作为工具使用 - 作为工具的 agent 独立运行，然后将结果返回给原始 agent。

例如，你可以将上面的翻译任务建模为工具调用：不是将任务交给特定语言的 agent，而是将其作为工具调用，然后在下一步使用结果。这样可以实现同时翻译多种语言等功能。

查看 [`agents_as_tools.py`](./agents_as_tools.py) 文件获取这种模式的示例。

## LLM 作为评判者

如果给出反馈，LLM 通常可以提高其输出质量。一个常见的模式是使用一个模型生成响应，然后使用第二个模型提供反馈。你甚至可以使用较小的模型进行初始生成，使用较大的模型进行反馈，以优化成本。

例如，你可以使用 LLM 生成故事的大纲，然后使用第二个 LLM 评估大纲并提供反馈。然后你可以使用这些反馈来改进大纲，重复这个过程直到 LLM 对大纲满意为止。

查看 [`llm_as_a_judge.py`](./llm_as_a_judge.py) 文件获取这种模式的示例。

## 并行化

并行运行多个 agent 是一种常见模式。这对于延迟很有用（例如，如果你有多个相互之间没有依赖关系的步骤），还有其他原因，例如生成多个响应并选择最佳响应。

查看 [`parallelization.py`](./parallelization.py) 文件获取这种模式的示例。它多次并行运行翻译 agent，然后选择最佳翻译。

## 保护措施

与并行化相关，你通常希望运行输入保护措施以确保输入有效。例如，如果你有一个客户支持 agent，你可能希望确保用户不是在寻求数学问题的帮助。

你可以通过并行化来做到这一点，而无需任何特殊的 Agents SDK 功能，但我们支持一种特殊的保护措施原语。保护措施可以有一个 "触发器" - 如果触发器被触发，agent 执行将立即停止，并引发 `GuardrailTripwireTriggered` 异常。

这对于延迟非常有用：例如，你可能有一个非常快速的模型来运行保护措施，一个较慢的模型来运行实际的 agent。你不希望等待慢模型完成，因此保护措施可以让你快速拒绝无效输入。

查看 [`input_guardrails.py`](./input_guardrails.py) 和 [`output_guardrails.py`](./output_guardrails.py) 文件获取这种模式的示例。
